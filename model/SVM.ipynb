{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0f6jEs5S3z0"
      },
      "source": [
        "# Group: 10\n",
        "# Rollno: 19EE10050, 19EC10041, 22CS60R18\n",
        "# Project Code: PSSVM\n",
        "# Project Title: Pulsar Star Classification using Support Vector Machines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJHSGKcJTTTM"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "9-LA3n9RS3oz"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas\n",
        "pandas.options.mode.chained_assignment = None  # default='warn'\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import process_time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from cvxopt import matrix, solvers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNbvNE0LTZFl"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "zIIzziEfTazW"
      },
      "outputs": [],
      "source": [
        "class Preprocessor:\n",
        "  '''Preprocessor'''\n",
        "\n",
        "  def __init__(self):\n",
        "    self.means = {}\n",
        "    self.stds = {}\n",
        "\n",
        "  def get_folds(self, p_csv, prediction_class):\n",
        "    '''\n",
        "        input: processed csv, prediction class\n",
        "        output: 5 folds\n",
        "        \n",
        "        Each fold contains (X_train, y_train, X_test, y_test)\n",
        "        X_train, X_test are nd-arrays\n",
        "        y_train, y_test are 1d-arrays\n",
        "        Usage: see task_1()\n",
        "    '''\n",
        "    folds = []\n",
        "    for train_index, test_index in self.__perform_5_fold(p_csv):\n",
        "        train_set = p_csv.iloc[train_index]\n",
        "        test_set = p_csv.iloc[test_index]\n",
        "\n",
        "        # seperate prediction class from other classes\n",
        "        X_train, y_train = self.separate_prediction_class(train_set, prediction_class)\n",
        "        X_test, y_test = self.separate_prediction_class(test_set, prediction_class)\n",
        "\n",
        "        X_train = X_train.to_numpy()\n",
        "        y_train = y_train[prediction_class].to_numpy()\n",
        "        X_test = X_test.to_numpy()\n",
        "        y_test = y_test[prediction_class].to_numpy()\n",
        "\n",
        "        folds.append((X_train, y_train, X_test, y_test))\n",
        "    \n",
        "    return folds\n",
        "\n",
        "  def __perform_5_fold(self, dataset):\n",
        "    '''\n",
        "        input: train set\n",
        "        output: generator object which generates one fold indices in one iteration.\n",
        "    '''\n",
        "\n",
        "    k_fold = KFold(n_splits=5, shuffle=True, random_state=6)\n",
        "    for train_index, test_index in k_fold.split(dataset):\n",
        "        yield train_index, test_index\n",
        "\n",
        "  def normalize_columns(self, df, prediction_class, test=False):\n",
        "    '''\n",
        "        Standardization (Z-score normalization)\n",
        "        x = (x - mean) / sd\n",
        "    '''\n",
        "    for column in df:\n",
        "      if column == prediction_class:\n",
        "        ind = (df[column] == 0)\n",
        "        df[column][ind] = -1\n",
        "        continue\n",
        "          \n",
        "      mean = None\n",
        "      std = None\n",
        "      if not test:\n",
        "        self.means[column] = df[column].mean()\n",
        "        self.stds[column] = df[column].std()\n",
        "      mean = self.means[column]\n",
        "      std = self.stds[column]\n",
        "      df[column] = (df[column] - mean) / std\n",
        "\n",
        "  def drop_outliers(self, X_csv, Y_csv):\n",
        "    limit = {}\n",
        "    drop_rows = []\n",
        "    n_columns = len(X_csv.columns)\n",
        "    for column in X_csv.columns:\n",
        "      Mean = X_csv[column].mean()\n",
        "      Std = X_csv[column].std()\n",
        "      limit[column] = Mean + 3 * Std\n",
        "\n",
        "    print('limits done')\n",
        "    for i, row in X_csv.iterrows():\n",
        "      n_col_outliers = 0\n",
        "      for column in X_csv.columns:\n",
        "        if (row[column] > limit[column]):\n",
        "            n_col_outliers += 1\n",
        "      if (2 * n_col_outliers > n_columns):\n",
        "        drop_rows.append(i)\n",
        "    print('dropping rows...')\n",
        "    return X_csv.drop(drop_rows), Y_csv.drop(drop_rows)\n",
        "\n",
        "  def separate_prediction_class(self, dataset, prediction_class):\n",
        "    '''\n",
        "        input: prediction class\n",
        "        output: X df, y df\n",
        "        Seperates prediction class from other classes\n",
        "    '''\n",
        "    Y = dataset[[prediction_class]]\n",
        "    X = dataset.drop([prediction_class], axis=1)\n",
        "    return X, Y\n",
        "\n",
        "  def process(self, csv_file, prediction_class):\n",
        "    '''\n",
        "        input: raw csv file\n",
        "        output: prcessed csv (dataframe)\n",
        "        1. Normalizes features [0,1]\n",
        "        Usage:\n",
        "            p = Preprocessor()\n",
        "            p_csv = p.process('hospital.csv', 'Stay')\n",
        "    '''\n",
        "    # read input\n",
        "    df = pandas.read_csv(csv_file)\n",
        "\n",
        "    # 14319 rows required 1.6GB of memory to store Kernel Matrix\n",
        "    df = df.iloc[:10000, :]\n",
        "\n",
        "    # split dataset into train and test\n",
        "    train, test = train_test_split(df, test_size=0.2, random_state=6)\n",
        "\n",
        "    # normalize columns\n",
        "    self.normalize_columns(train, prediction_class)\n",
        "    self.normalize_columns(test, prediction_class, test=True)\n",
        "\n",
        "    # separate prediction class\n",
        "    X_train, Y_train = Preprocessor().separate_prediction_class(train, 'Class')\n",
        "    X_test, Y_test = Preprocessor().separate_prediction_class(test, 'Class')\n",
        "\n",
        "    return X_train, Y_train.iloc[:, 0], X_test, Y_test.iloc[:, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlP5ieVLVIo2"
      },
      "source": [
        "# custom SVM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM:\n",
        "\n",
        "  def __init__(self, kernel='linear', C=1.0, gamma=0.125):\n",
        "    self.kernel = kernel\n",
        "    self.C = C\n",
        "    self.gamma = gamma\n",
        "    self.alphas = None\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "\n",
        "  def kernel_function(self, x1, x2):\n",
        "    if self.kernel == 'linear':\n",
        "      return np.dot(x1, x2)\n",
        "\n",
        "    elif self.kernel == 'quadratic':\n",
        "      return (np.dot(x1, x2)+1) ** 2 \n",
        "\n",
        "    else:\n",
        "      dist = np.dot((x1 - x2).T, (x1 - x2))\n",
        "      K = np.exp(-self.gamma * dist)\n",
        "      return K\n",
        "\n",
        "  def calculate_weights(self, alphas, x, y):\n",
        "    y = y.reshape(-1,1) # Convert the y into same form as alphas... dim(alphas) : m * 1\n",
        "    w = ((y*alphas).T)@x\n",
        "    return w\n",
        "\n",
        "  def calculate_bias(self, w, x_sv, y_sv):\n",
        "    return (y_sv - np.dot(x_sv,w))\n",
        "\n",
        "  def qp_solver(self, x, y):\n",
        "    m, n = x.shape # m : no. of examples in training data, n : no. of attributes in training data\n",
        "    K = np.zeros((m, m))\n",
        "    for i in tqdm(range(m)):\n",
        "      for j in range(i, m):\n",
        "        K[i][j] = self.kernel_function(x[i], x[j])\n",
        "        K[j][i] = K[i][j] # symmetric kernel function\n",
        "\n",
        "    y = y.astype(float)\n",
        "    coeff = np.outer(y,y)\n",
        "    P = matrix(coeff * K)\n",
        "    q = matrix(np.ones((m, 1)) * -1)\n",
        "    A = matrix(y.reshape(1, -1))\n",
        "    b = matrix(np.zeros(1))\n",
        "    G = matrix(np.vstack((np.eye(m)*-1, np.eye(m))))\n",
        "    h = matrix(np.hstack((np.zeros(m), np.ones(m) * self.C)))\n",
        "    opts = {'maxiters' : 10, 'show_progress' : True}\n",
        "    solution = solvers.qp(P, q, G, h, A, b, options=opts)\n",
        "    return solution\n",
        "\n",
        "  def fit(self, X_train, y_train):\n",
        "    print(\"--------------------------------Training--------------------------------\")\n",
        "    t1 = process_time()\n",
        "    x, y = X_train.to_numpy(), y_train.to_numpy()\n",
        "    print('dataset size: {}, dimension: {}'.format(len(x), len(x[0])))\n",
        "\n",
        "    sol = self.qp_solver(x, y)\n",
        "    alphas = np.array(sol['x'])\n",
        "\n",
        "    sv = (alphas > 1e-6).flatten() # support vectors indices\n",
        "    x_sv = x[sv]\n",
        "    y_sv = y[sv]\n",
        "\n",
        "    weights = self.calculate_weights(alphas, x, y) # Using the entire dataset to calculate weights\n",
        "    b = self.calculate_bias(weights[0], x_sv, y_sv) # Using only the support vectors to calculate b vector\n",
        "    bias = np.sum(b)/b.size  # Take average over all the support vectors to get the bias\n",
        "\n",
        "    t2 = process_time()\n",
        "\n",
        "    print('\\nResults ')\n",
        "    print('Weights: ', weights)\n",
        "    print('Bias: ', bias)\n",
        "    print(\"\\nTraining Time: \", t2 - t1)\n",
        "    print(\"------------------------------------------------------------------------\")\n",
        "\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "    self.alphas = alphas\n",
        "    return weights, bias\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    X_test = X_test if isinstance(X_test, np.ndarray) else X_test.to_numpy()\n",
        "    y_pred = []\n",
        "    for x in X_test:\n",
        "      if np.dot(self.weights, x) + self.bias > 0:\n",
        "        y_pred.append(1)\n",
        "      else:\n",
        "        y_pred.append(-1)\n",
        "    return y_pred    \n",
        "\n",
        "  def score(self, y_test, y_pred):\n",
        "    print(\"\\nAccuracy: \", accuracy_score(y_test.to_list(), y_pred)) # Accuracy"
      ],
      "metadata": {
        "id": "bRvEtMJWKMZf"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Function"
      ],
      "metadata": {
        "id": "5EPzNxymj73g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(kernel='linear', C=1.0, gamma=0.125, is_sklearn=True):\n",
        "  kernel = 'poly' if (is_sklearn == True and kernel == 'quadratic') else kernel\n",
        "  model = svm.SVC(C=C, kernel=kernel, degree=2, gamma=gamma) if (is_sklearn == True) else SVM(kernel=kernel, C=C, gamma=gamma)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print('\\nAccuracy: ', accuracy)"
      ],
      "metadata": {
        "id": "YsVTjcI0lMZy"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "YcoY1l_jj-OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test = Preprocessor().process(\"pulsar_star_dataset.csv\", \"Class\")"
      ],
      "metadata": {
        "id": "lWN6YbccOgrq"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### custom SVM"
      ],
      "metadata": {
        "id": "Fjr7Rl3su3uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Note : kernel takes 3 types of values\n",
        "          1. 'linear'\n",
        "          2. 'quadratic'\n",
        "          3. 'rbf'\n",
        "'''\n",
        "\n",
        "train(kernel='linear', C=1, gamma=0.125, is_sklearn=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGKiarvmKMEr",
        "outputId": "17756d5b-8a7e-4968-b06c-de60e14fe099"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------Training--------------------------------\n",
            "dataset size: 8000, dimension: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8000/8000 [01:53<00:00, 70.41it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -1.0337e+03 -1.9709e+04  1e+05  3e+00  3e-13\n",
            " 1: -6.5074e+02 -1.2196e+04  2e+04  5e-01  3e-13\n",
            " 2: -4.8211e+02 -4.3674e+03  6e+03  1e-01  2e-13\n",
            " 3: -4.1771e+02 -1.9409e+03  2e+03  3e-02  2e-13\n",
            " 4: -4.1381e+02 -1.2271e+03  1e+03  1e-02  1e-13\n",
            " 5: -4.2557e+02 -9.9135e+02  7e+02  8e-03  1e-13\n",
            " 6: -4.3553e+02 -8.6677e+02  5e+02  5e-03  1e-13\n",
            " 7: -4.4514e+02 -7.9323e+02  4e+02  4e-03  2e-13\n",
            " 8: -4.5004e+02 -7.6208e+02  3e+02  3e-03  1e-13\n",
            " 9: -4.5471e+02 -7.2076e+02  3e+02  2e-03  2e-13\n",
            "10: -4.6323e+02 -6.7430e+02  2e+02  1e-03  2e-13\n",
            "Terminated (maximum number of iterations reached).\n",
            "\n",
            "Results \n",
            "Weights:  [[ 0.55434971 -0.0806169   4.43471986 -1.9126303  -0.41612752  0.56026009\n",
            "   0.17898021 -0.28937026]]\n",
            "Bias:  -0.747\n",
            "\n",
            "Training Time:  895.799492109\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "Accuracy:  0.9585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(kernel='linear', C=0.01, gamma=0.125, is_sklearn=False)"
      ],
      "metadata": {
        "id": "Djx1KoVU6_sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(kernel='linear', C=0.1, gamma=0.125, is_sklearn=False)"
      ],
      "metadata": {
        "id": "GLxh59cN7Cvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(kernel='linear', C=10, gamma=0.125, is_sklearn=False)"
      ],
      "metadata": {
        "id": "LROiYckC7F4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(kernel='linear', C=100, gamma=0.125, is_sklearn=False)"
      ],
      "metadata": {
        "id": "CfAi5AYL7HId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0xJ7S55U9pv"
      },
      "source": [
        "### sklearn SVM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Note : kernel takes 3 types of values\n",
        "          1. 'linear'\n",
        "          2. 'quadratic'\n",
        "          3. 'rbf'\n",
        "'''\n",
        "\n",
        "train(kernel='linear', C=1, gamma=0.125, is_sklearn=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0zcUO-EvSo5",
        "outputId": "e74a6215-3d9b-4088-8ede-a3286d911d31"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy:  0.9725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eG7EqHCTs8M"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "NRJu2Wo_oIWn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "vDIcjfIfTrSg"
      },
      "outputs": [],
      "source": [
        "def make_meshgrid(x, y, h=.02):\n",
        "  x_min, x_max = x.min() - 1, x.max() + 1\n",
        "  y_min, y_max = y.min() - 1, y.max() + 1\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "  return xx, yy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "m_ScKnTOUsV4"
      },
      "outputs": [],
      "source": [
        "def plot_contours(ax, clf, xx, yy, is_sklearn=False, **params):\n",
        "  Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  Z = Z.reshape(xx.shape) if is_sklearn == True else np.array(Z).reshape(xx.shape)\n",
        "  out = ax.contourf(xx, yy, Z, **params)\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "pLRH2EkoUwu8"
      },
      "outputs": [],
      "source": [
        "def visualize_boundary(kernel='linear', C=1, gamma=0.125, is_sklearn=True):\n",
        "    X_train, y_train, X_test, y_test = Preprocessor().process(\"pulsar_star_dataset.csv\", \"Class\")\n",
        "    kernel = 'poly' if (is_sklearn == True and kernel == 'quadratic') else kernel\n",
        "    model = svm.SVC(kernel=kernel, C=C, gamma=gamma) if (is_sklearn == True) else SVM(kernel=kernel, C=C, gamma=gamma)\n",
        "    model.fit(X_train.iloc[:, 0:2], y_train)\n",
        "    y_pred = model.predict(X_test.iloc[:, 0:2])\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'Accuracy of {kernel} kernel: {accuracy}')\n",
        "\n",
        "    title = f\"SVC with {kernel} kernel\"\n",
        "    \n",
        "    X0, X1 = X_train.iloc[:, 0], X_train.iloc[:, 1]\n",
        "    y = y_train\n",
        "\n",
        "    # Set-up 2x2 grid for plotting.\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # setup grid\n",
        "    xx, yy = make_meshgrid(X0, X1)\n",
        "\n",
        "    plot_contours(ax, model, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
        "    ax.set_ylabel(X_train.columns[0])\n",
        "    ax.set_xlabel(X_train.columns[1])\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    ax.set_title(title)\n",
        "    ax.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### custom SVM"
      ],
      "metadata": {
        "id": "XLKIntn5oLaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize_boundary(kernel= <desired kernel here>, C=<desired C here>, gamma = <desired C here>, is_sklearn=False)"
      ],
      "metadata": {
        "id": "VKjJRHkjoG7x"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sklearn SVM"
      ],
      "metadata": {
        "id": "fQ4BxQrJoMtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize_boundary(kernel= <desired kernel here>, C=<desired C here>, gamma = <desired C here>, is_sklearn=True)"
      ],
      "metadata": {
        "id": "HLZsHsG7oOz6"
      },
      "execution_count": 205,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PJHSGKcJTTTM",
        "qNbvNE0LTZFl",
        "SlP5ieVLVIo2",
        "5EPzNxymj73g",
        "Fjr7Rl3su3uc",
        "c0xJ7S55U9pv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}