{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Group: 10\n","# Rollno: 19EE10050, 19EC10041, 22CS60R18\n","# Project Code: PSSVM\n","# Project Title: Pulsar Star Classification using Support Vector Machines"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class SVM:\n","    \n","    def __init__(self, C=1.0):\n","        self.C = C\n","        self.W = 0\n","        self.b = 0\n","    \n","    def hinge_loss(self, W, b, X, Y):\n","        W = np.reshape(W, (-1, 1))\n","        loss = 0.0\n","        loss += 0.5 * np.dot(W.T, W)[0][0]\n","        X = np.reshape(X, (-1, 1))\n","        m = X.shape[0]\n","        for i in range(m):\n","            ti = Y[i] * (np.dot(W.T, X[i]) + b)\n","            loss += self.C * max(0, (1 - ti))\n","        return loss[0]\n","\n","    def fit(self, X, Y, batch_size=100, learning_rate=0.001, maxItr=300):\n","        X = np.reshape(X, (-1, 1))\n","        Y = np.reshape(Y, (-1, 1))\n","        n_features = X.shape[1]\n","        n_samples = X.shape[0]\n","        n = learning_rate\n","        c = self.C\n","        W = np.zeros((n_features, 1))\n","        bias = 0\n","        losses = []\n","        for i in range(maxItr):\n","            l = self.hinge_loss(W, bias, X, Y)\n","            losses.append(l)\n","            ids = np.arange(n_samples)\n","            np.random.shuffle(ids)\n","            for batch_start in range(0, n_samples, batch_size):\n","                gradw = 0\n","                gradb = 0\n","                for j in range(batch_start, batch_start + batch_size):\n","                    if j < n_samples:\n","                        i = ids[j]\n","                        ti = Y[i] * (np.dot(W.T, X[i]) + bias)\n","                        if ti > 1:\n","                            gradw += 0\n","                            gradb += 0\n","                        else:\n","                            gradw += c * Y[i] * X[i]\n","                            gradb += c * Y[i]\n","                W = W - n * W + n * gradw\n","                bias = bias + n * gradb\n","        \n","        print(\"Final loss is\", l)\n","        self.W = W\n","        self.b = bias\n","        return W, bias, losses\n","    \n","    def predict(self, X):\n","        X = np.reshape(X, (-1, 1))\n","        return np.sign(np.dot(X, self.W) + self.b)\n","    \n","    def score(self, X, Y):\n","        X = np.reshape(X, (-1, 1))\n","        Y = np.reshape(Y, (-1, 1))\n","        Y_ = self.predict(X)\n","        return np.sum(Y_ == Y) / Y.shape[0]\n","    \n","    def visualize(self, X, Y, losses):\n","        X = np.reshape(X, (-1, 1))\n","        Y = np.reshape(Y, (-1, 1))\n","        plt.figure(0)\n","        plt.scatter(X, Y)\n","        plt.show()\n","        plt.figure(1)\n","        plt.plot(losses)\n","        plt.show()\n","        return 0\n","\n","if __name__ == \"__main__\":\n","    data = pd.read_csv(\"data_2d.csv\", header=None)\n","    X = data.iloc[:, 0]\n","    Y = data.iloc[:, 1]\n","    labels = data.iloc[:, 2]\n","    svm = SVM()\n","    W, b, losses = svm.fit(X, labels)\n","    svm.visualize(X, labels, losses)\n","    print(svm.score(X, labels))\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":2}
